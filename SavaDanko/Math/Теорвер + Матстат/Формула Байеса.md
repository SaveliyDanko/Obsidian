Пусть $B_1, B_2, \dots, B_n$ — полная группа взаимно исключающих событий, одно из которых обязательно происходит, а $A$ — некоторое наблюдаемое событие.
Тогда вероятность наступления события $B_i$ после того, как произошло $A$, вычисляется по формуле:
$P(B_i \mid A) = \frac{P(B_i) \cdot P(A \mid B_i)}{P(A)}$
где:
- $P(B_i \mid A)$ — апостериорная вероятность (обновлённая после наблюдения $A$). 

##### Доказательство
**Шаг 1: По определению условной вероятности**
$P(A \mid B_i) = \frac{P(A \cap B_i)}{P(B_i)} \quad \Rightarrow \quad P(A \cap B_i) = P(A \mid B_i) \cdot P(B_i)$

**Шаг 2: Аналогично для обратной условной вероятности**
$P(B_i \mid A) = \frac{P(A \cap B_i)}{P(A)} \quad \Rightarrow \quad P(B_i \mid A) = \frac{P(A \mid B_i) \cdot P(B_i)}{P(A)}$

**Формула полной вероятности**
Чтобы раскрыть знаменатель $P(A)$, воспользуемся формулой полной вероятности:
$P(A) = P(A \cap B_1) + P(A \cap B_2) + \dots + P(A \cap B_n)$

С учётом выражения $P(A \cap B_j) = P(A \mid B_j) \cdot P(B_j)$, получаем:
$P(A) = \sum_{j=1}^{n} P(A \mid B_j) \cdot P(B_j)$

**Итоговая формула Байеса (полная форма)**
$P(B_i \mid A) = \frac{P(A \mid B_i) \cdot P(B_i)}{\sum\limits_{j=1}^{n} P(A \mid B_j) \cdot P(B_j)}$
