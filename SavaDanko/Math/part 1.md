**Обобщающая способность (generalization ability)** — это свойство модели машинного обучения, заключающееся в способности выдавать корректные предсказания на новых, ранее не встречавшихся примерах из того же распределения, из которого были получены обучающие данные.

Пусть:
- $\mathcal{X}$ — пространство признаков (входов)
- $\mathcal{Y}$ — пространство меток (выходов)
- $\mathcal{D}$ — неизвестное вероятностное распределение над $\mathcal{X} \times \mathcal{Y}$, из которого поступают данные
- $S = \{(x_i, y_i)\}_{i=1}^n \sim \mathcal{D}^n$ — обучающая выборка из $n$ независимых и одинаково распределённых примеров
- $h: \mathcal{X} \rightarrow \mathcal{Y}$ — гипотеза (модель), построенная на основе выборки $S$  
- $\ell(h(x), y)$ — функция потерь, измеряющая ошибку модели на примере $(x, y)$.
    
Тогда:
- Эмпирический риск (ошибка на обучающей выборке):
    $\hat{R}(h) = \frac{1}{n} \sum_{i=1}^n \ell(h(x_i), y_i)$
- Ожидаемый риск (истинная ошибка на новых данных):
    $R(h) = \mathbb{E}_{(x, y) \sim \mathcal{D}}[\ell(h(x), y)]$

Обобщающая способность модели $h$ определяется как степень близости между эмпирическим риском $\hat{R}(h)$ и ожидаемым риском $R(h)$.
Чем меньше разница $|R(h) - \hat{R}(h)|$, тем выше обобщающая способность модели.

---
**Определение: Теория VC-измеримости**
**Теория VC-измеримости** — это раздел статистического обучения, сформулированный Владимиром Вапником и Алексеем Червоненкисом, который изучает связь между способностью класса гипотез (моделей) разделять множества объектов различными способами и возможностью этих моделей обобщать, т.е. демонстрировать низкую ошибку на новых, ранее не встречавшихся данных.

**Формализация**
Пусть:
- $\mathcal{X}$ — множество входов (пространство объектов)
- $\mathcal{H}$ — класс булевых гипотез $h: \mathcal{X} \to \{0, 1\}$
- $S = \{x_1, \dots, x_n\} \subset \mathcal{X}$ — конечное множество точек (подмножество пространства объектов).
    

**Разбиение множества (shattering)**
Множество $S$ называется разбиваемым классом гипотез $\mathcal{H}$, если:
$\forall y \in \{0, 1\}^n \ \exists h \in \mathcal{H}: \forall i \in \{1, \dots, n\},\ h(x_i) = y_i$


**VC-измеримость**
VC-измеримость (или размерность Вапника–Червоненкиса) класса гипотез $\mathcal{H}$, обозначаемая как $\mathrm{VC}(\mathcal{H})$, — это наибольшее целое число $d$, для которого существует множество $S \subset \mathcal{X}$, $|S| = d$, такое что $\mathcal{H}$ разбивает $S$, но не существует множества из $d+1$ точек, которое также можно разбить всеми возможными способами с помощью гипотез из $\mathcal{H}$.

---
**Переобучение (overfitting)**
**Переобучение** — это явление, при котором модель машинного обучения демонстрирует низкую ошибку на обучающей выборке, но высокую ошибку на новых, ранее не встречавшихся данных, вследствие чрезмерной адаптации к обучающим данным, включая шум, выбросы или случайные флуктуации в данных.

Пусть:
- $\hat{R}(h)$ — эмпирический риск (ошибка на обучающей выборке),
- $R(h)$ — истинный риск (ошибка на реальном распределении данных)
- $h \in \mathcal{H}$ — обученная модель (гипотеза).
    
Тогда переобучение наблюдается, если:
$\hat{R}(h) \ll R(h)$
и разница $|R(h) - \hat{R}(h)|$ значительна, то есть модель не обладает достаточной обобщающей способностью.

**Недообучение (underfitting)**
Недообучение — это ситуация, при которой модель машинного обучения не способна адекватно захватить зависимость между признаками и целевыми значениями, вследствие недостаточной сложности модели или неэффективного обучения. В этом случае модель демонстрирует высокую ошибку как на обучающих, так и на тестовых данных.


Пусть модель $h \in \mathcal{H}$ обучена на выборке $S$, тогда недообучение наблюдается, если:
$\hat{R}(h) \approx R(h) \gg 0$
то есть модель не достигает хорошего качества даже на обучении.

---
**Обучающая выборка (training set)**
Обучающая выборка — это подмножество данных, отобранное из общего распределения $\mathcal{D}$, которое используется для построения (обучения) модели машинного обучения путём оптимизации параметров модели на основе функции потерь.

Пусть:
- $\mathcal{X}$ — пространство входных признаков,
- $\mathcal{Y}$ — пространство выходных меток (целевых значений),
- $\mathcal{D}$ — истинное (неизвестное) распределение данных на $\mathcal{X} \times \mathcal{Y}$
- $S_{\text{train}} = \{(x_i, y_i)\}_{i=1}^{n} \sim \mathcal{D}^n$ — обучающая выборка.
    
Тогда:
- Эта выборка используется для построения гипотезы $h \in \mathcal{H}$ с целью минимизации эмпирического риска:
$\hat{R}(h) = \frac{1}{n} \sum_{i=1}^{n} \ell(h(x_i), y_i)$

**Тестовая выборка (test set)**
Тестовая выборка — это подмножество данных, независимое от обучающей выборки, которое используется для оценки качества обученной модели на новых, ранее не встречавшихся данных, с целью приближённой оценки её обобщающей способности.

Пусть:
- $S_{\text{test}} = \{(x_j, y_j)\}_{j=1}^{m} \sim \mathcal{D}^m$, $S_{\text{test}} \cap S_{\text{train}} = \emptyset$,
- $h$ — гипотеза, обученная на $S_{\text{train}}$

Тогда ошибка на тестовой выборке (оценка истинного риска) вычисляется как:
$\hat{R}_{\text{test}}(h) = \frac{1}{m} \sum_{j=1}^{m} \ell(h(x_j), y_j)$

---
**Гипотезное пространство (hypothesis space)**
Гипотезное пространство — это множество всех допустимых моделей (функций), среди которых алгоритм обучения выбирает наилучшую гипотезу на основе обучающей выборки и функции потерь.

Пусть:
- $\mathcal{X}$ — пространство входных данных (признаков),
- $\mathcal{Y}$ — пространство целевых значений
- $\mathcal{H} \subseteq \{ h: \mathcal{X} \to \mathcal{Y} \}$ — гипотезное пространство — множество всех моделей $h$, доступных алгоритму обучения.
    
Алгоритм обучения ищет:
$h^* = \arg\min_{h \in \mathcal{H}} \hat{R}(h)$
где $\hat{R}(h)$ — эмпирический риск (ошибка на обучающей выборке).

**Модельная сложность (model complexity)**
Модельная сложность — это мера выразительной способности модели, то есть способности аппроксимировать (приближать) разнообразные зависимости между входными и выходными данными.
Чем выше модельная сложность, тем шире гипотезное пространство, и тем выше риск переобучения при недостаточном объёме данных.

Модельная сложность может быть количественно выражена через:
- Размерность VC (VC-dimension) — для булевых гипотез
- Размерность гипотезного пространства (например, число параметров $\theta$)
- Эффективную сложность (через регуляризацию, норму весов и др.),
- Rademacher complexity, covering numbers, description length и др.

---
**Мера вместимости модели (model capacity)**
Вместимость модели — это количественная характеристика, отражающая способность модели аппроксимировать широкий класс функций или закономерностей.  
Она определяет, насколько сложные зависимости между входными и выходными переменными модель способна выразить.

**Необходимость введения меры вместимости**
Введение меры вместимости необходимо для теоретического обоснования и контроля способности модели к обобщению.  
Без понимания вместимости невозможно: 
- определить, будет ли модель переобучаться или недообучаться    
- установить минимальный объём обучающих данных,    
- построить границы обобщающей ошибки    
- сравнить разные классы моделей с точки зрения сложности и риска переобучения.    

Пусть:
- $\mathcal{H}$ — гипотезное пространство (множество моделей),
- $\mathcal{D}$ — истинное распределение данных,
- $\ell(h(x), y)$ — функция потерь
- $R(h)$ — истинный риск,
- $\hat{R}(h)$ — эмпирический риск.
    
Тогда разность $|R(h) - \hat{R}(h)|$ зависит от вместимости гипотезного пространства $\mathcal{H}$.

Чтобы оценить эту разницу, вводятся меры вместимости:
- VC-измеримость — для булевых функций
- Rademacher complexity — оценка способности класса гипотез подстраиваться под случайные метки
- Covering number / fat-shattering dimension — более общие геометрические меры.
    